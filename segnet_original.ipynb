{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input, metrics\n",
    "from tensorflow.keras import layers #Conv2D, Layer, BatchNormalization, Activation\n",
    "from tensorflow.keras import optimizers #Adam\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext tensorboard\n",
    "from tensorboard import notebook\n",
    "import datetime,os\n",
    "import numpy as np\n",
    "\n",
    "from metrics.intersection_over_union import iou\n",
    "from pooling_layers.max_pooling import MaxPoolingWithArgmax2D\n",
    "from pooling_layers.max_unpooling import MaxUnpooling2D\n",
    "from data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegNet(input_shape, batch_size, n_labels=2, kernel=3, pool_size=(2, 2), output_mode=\"softmax\", model_summary=None):\n",
    "    # encoder\n",
    "    inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    conv_1 = layers.Conv2D(64, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(inputs)\n",
    "    conv_1 = layers.BatchNormalization()(conv_1)\n",
    "    conv_1 = layers.Activation(\"relu\")(conv_1)\n",
    "    conv_2 = layers.Conv2D(64, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_1)\n",
    "    conv_2 = layers.BatchNormalization()(conv_2)\n",
    "    conv_2 = layers.Activation(\"relu\")(conv_2)\n",
    "\n",
    "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
    "\n",
    "    conv_3 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(pool_1)\n",
    "    conv_3 = layers.BatchNormalization()(conv_3)\n",
    "    conv_3 = layers.Activation(\"relu\")(conv_3)\n",
    "    conv_4 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_3)\n",
    "    conv_4 = layers.BatchNormalization()(conv_4)\n",
    "    conv_4 = layers.Activation(\"relu\")(conv_4)\n",
    "\n",
    "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
    "\n",
    "    conv_5 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(pool_2)\n",
    "    conv_5 = layers.BatchNormalization()(conv_5)\n",
    "    conv_5 = layers.Activation(\"relu\")(conv_5)\n",
    "    conv_6 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_5)\n",
    "    conv_6 = layers.BatchNormalization()(conv_6)\n",
    "    conv_6 = layers.Activation(\"relu\")(conv_6)\n",
    "    conv_7 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_6)\n",
    "    conv_7 = layers.BatchNormalization()(conv_7)\n",
    "    conv_7 = layers.Activation(\"relu\")(conv_7)\n",
    "\n",
    "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
    "\n",
    "    conv_8 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(pool_3)\n",
    "    conv_8 = layers.BatchNormalization()(conv_8)\n",
    "    conv_8 = layers.Activation(\"relu\")(conv_8)\n",
    "    conv_9 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_8)\n",
    "    conv_9 = layers.BatchNormalization()(conv_9)\n",
    "    conv_9 = layers.Activation(\"relu\")(conv_9)\n",
    "    conv_10 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_9)\n",
    "    conv_10 = layers.BatchNormalization()(conv_10)\n",
    "    conv_10 = layers.Activation(\"relu\")(conv_10)\n",
    "\n",
    "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
    "\n",
    "    conv_11 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(pool_4)\n",
    "    conv_11 = layers.BatchNormalization()(conv_11)\n",
    "    conv_11 = layers.Activation(\"relu\")(conv_11)\n",
    "    conv_12 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_11)\n",
    "    conv_12 = layers.BatchNormalization()(conv_12)\n",
    "    conv_12 = layers.Activation(\"relu\")(conv_12)\n",
    "    conv_13 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_12)\n",
    "    conv_13 = layers.BatchNormalization()(conv_13)\n",
    "    conv_13 = layers.Activation(\"relu\")(conv_13)\n",
    "\n",
    "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
    "    print(\"Build enceder done..\")\n",
    "\n",
    "    # decoder\n",
    "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
    "\n",
    "    conv_14 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(unpool_1)\n",
    "    conv_14 = layers.BatchNormalization()(conv_14)\n",
    "    conv_14 = layers.Activation(\"relu\")(conv_14)\n",
    "    conv_15 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_14)\n",
    "    conv_15 = layers.BatchNormalization()(conv_15)\n",
    "    conv_15 = layers.Activation(\"relu\")(conv_15)\n",
    "    conv_16 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_15)\n",
    "    conv_16 = layers.BatchNormalization()(conv_16)\n",
    "    conv_16 = layers.Activation(\"relu\")(conv_16)\n",
    "\n",
    "    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n",
    "\n",
    "    conv_17 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(unpool_2)\n",
    "    conv_17 = layers.BatchNormalization()(conv_17)\n",
    "    conv_17 = layers.Activation(\"relu\")(conv_17)\n",
    "    conv_18 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_17)\n",
    "    conv_18 = layers.BatchNormalization()(conv_18)\n",
    "    conv_18 = layers.Activation(\"relu\")(conv_18)\n",
    "    conv_19 = layers.Conv2D(256, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_18)\n",
    "    conv_19 = layers.BatchNormalization()(conv_19)\n",
    "    conv_19 = layers.Activation(\"relu\")(conv_19)\n",
    "    #reduce the number of feature maps to 128, \n",
    "    #since mask_3 has 128 feature maps\n",
    "    conv_19 = layers.Conv2D(128, (1, 1))(conv_19)\n",
    "    \n",
    "\n",
    "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
    "\n",
    "    conv_20 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(unpool_3)\n",
    "    conv_20 = layers.BatchNormalization()(conv_20)\n",
    "    conv_20 = layers.Activation(\"relu\")(conv_20)\n",
    "    conv_21 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_20)\n",
    "    conv_21 = layers.BatchNormalization()(conv_21)\n",
    "    conv_21 = layers.Activation(\"relu\")(conv_21)\n",
    "    conv_22 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_21)\n",
    "    conv_22 = layers.BatchNormalization()(conv_22)\n",
    "    conv_22 = layers.Activation(\"relu\")(conv_22)\n",
    "\n",
    "    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n",
    "\n",
    "    conv_23 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(unpool_4)\n",
    "    conv_23 = layers.BatchNormalization()(conv_23)\n",
    "    conv_23 = layers.Activation(\"relu\")(conv_23)\n",
    "    conv_24 = layers.Conv2D(128, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_23)\n",
    "    conv_24 = layers.BatchNormalization()(conv_24)\n",
    "    conv_24 = layers.Activation(\"relu\")(conv_24)\n",
    "    #reduce the number of feature maps to 64, \n",
    "    #since mask_1 has 64 feature maps\n",
    "    conv_24 = layers.Conv2D(64, (1, 1))(conv_24)\n",
    "    \n",
    "\n",
    "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
    "\n",
    "    conv_25 = layers.Conv2D(64, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(unpool_5)\n",
    "    conv_25 = layers.BatchNormalization()(conv_25)\n",
    "    conv_25 = layers.Activation(\"relu\")(conv_25)\n",
    "    conv_26 = layers.Conv2D(64, (kernel, kernel), padding=\"same\", kernel_initializer = 'he_normal')(conv_25)\n",
    "    conv_26 = layers.BatchNormalization()(conv_26)\n",
    "    conv_26 = layers.Activation(\"relu\")(conv_26)\n",
    "\n",
    "    out=layers.Conv2D(n_labels,1, activation = output_mode)(conv_26)\n",
    "    print(\"Build decoder done..\")\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out, name=\"SegNet\")\n",
    "    model.compile(optimizer = optimizers.Adam(lr = 1e-3), loss = 'categorical_crossentropy',metrics=[iou,'accuracy'])\n",
    "\n",
    "    if model_summary is True:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build enceder done..\n",
      "Build decoder done..\n",
      "Model: \"SegNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(16, 256, 256, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (16, 256, 256, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (16, 256, 256, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (16, 256, 256, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (16, 256, 256, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (16, 256, 256, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (16, 256, 256, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_5 (Ma [(16, 128, 128, 64), 0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (16, 128, 128, 128)  73856       max_pooling_with_argmax2d_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (16, 128, 128, 128)  512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (16, 128, 128, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (16, 128, 128, 128)  147584      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (16, 128, 128, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (16, 128, 128, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_6 (Ma [(16, 64, 64, 128),  0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (16, 64, 64, 128)    147584      max_pooling_with_argmax2d_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (16, 64, 64, 128)    512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (16, 64, 64, 128)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (16, 64, 64, 128)    147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (16, 64, 64, 128)    512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (16, 64, 64, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (16, 64, 64, 128)    147584      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (16, 64, 64, 128)    512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (16, 64, 64, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_7 (Ma [(16, 32, 32, 128),  0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (16, 32, 32, 256)    295168      max_pooling_with_argmax2d_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (16, 32, 32, 256)    1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (16, 32, 32, 256)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (16, 32, 32, 256)    590080      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (16, 32, 32, 256)    1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (16, 32, 32, 256)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (16, 32, 32, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (16, 32, 32, 256)    1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (16, 32, 32, 256)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_8 (Ma [(16, 16, 16, 256),  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (16, 16, 16, 256)    590080      max_pooling_with_argmax2d_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (16, 16, 16, 256)    1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (16, 16, 16, 256)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (16, 16, 16, 256)    590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (16, 16, 16, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (16, 16, 16, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (16, 16, 16, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (16, 16, 16, 256)    1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (16, 16, 16, 256)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_9 (Ma [(16, 8, 8, 256), (1 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_5 (MaxUnpooling (16, 16, 16, 256)    0           max_pooling_with_argmax2d_9[0][0]\n",
      "                                                                 max_pooling_with_argmax2d_9[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (16, 16, 16, 256)    590080      max_unpooling2d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (16, 16, 16, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (16, 16, 16, 256)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (16, 16, 16, 256)    590080      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (16, 16, 16, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (16, 16, 16, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (16, 16, 16, 256)    590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (16, 16, 16, 256)    1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (16, 16, 16, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_6 (MaxUnpooling (16, 32, 32, 256)    0           activation_41[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_8[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (16, 32, 32, 256)    590080      max_unpooling2d_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (16, 32, 32, 256)    1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (16, 32, 32, 256)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (16, 32, 32, 256)    590080      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (16, 32, 32, 256)    1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (16, 32, 32, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (16, 32, 32, 256)    590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (16, 32, 32, 256)    1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (16, 32, 32, 256)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (16, 32, 32, 128)    32896       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_7 (MaxUnpooling (16, 64, 64, 128)    0           conv2d_48[0][0]                  \n",
      "                                                                 max_pooling_with_argmax2d_7[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (16, 64, 64, 128)    147584      max_unpooling2d_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (16, 64, 64, 128)    512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (16, 64, 64, 128)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (16, 64, 64, 128)    147584      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (16, 64, 64, 128)    512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (16, 64, 64, 128)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (16, 64, 64, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (16, 64, 64, 128)    512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (16, 64, 64, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_8 (MaxUnpooling (16, 128, 128, 128)  0           activation_47[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_6[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (16, 128, 128, 128)  147584      max_unpooling2d_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (16, 128, 128, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (16, 128, 128, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (16, 128, 128, 128)  147584      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (16, 128, 128, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (16, 128, 128, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (16, 128, 128, 64)   8256        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_9 (MaxUnpooling (16, 256, 256, 64)   0           conv2d_54[0][0]                  \n",
      "                                                                 max_pooling_with_argmax2d_5[0][1]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (16, 256, 256, 64)   36928       max_unpooling2d_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (16, 256, 256, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (16, 256, 256, 64)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (16, 256, 256, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (16, 256, 256, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (16, 256, 256, 64)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (16, 256, 256, 2)    130         activation_51[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,360,450\n",
      "Trainable params: 8,351,234\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3936 images belonging to 2 classes.\n",
      "Found 3936 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Found 1344 images belonging to 2 classes.\n",
      "Found 1344 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 246 steps, validate for 84 steps\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layers with arguments in `__init__` must override `get_config`.\n",
      "Epoch 1/3\n",
      "245/246 [============================>.] - ETA: 1s - loss: 0.0135 - iou: 0.8653 - accuracy: 0.9948\n",
      "Epoch 00001: iou improved from -inf to 0.86532, saving model to trained_models/segnet_original.h5\n",
      "246/246 [==============================] - 337s 1s/step - loss: 0.0135 - iou: 0.8653 - accuracy: 0.9948 - val_loss: 0.0192 - val_iou: 0.8174 - val_accuracy: 0.9934\n",
      "Epoch 2/3\n",
      "245/246 [============================>.] - ETA: 1s - loss: 0.0134 - iou: 0.8669 - accuracy: 0.9949\n",
      "Epoch 00002: iou improved from 0.86532 to 0.86682, saving model to trained_models/segnet_original.h5\n",
      "246/246 [==============================] - 320s 1s/step - loss: 0.0134 - iou: 0.8668 - accuracy: 0.9949 - val_loss: 0.0182 - val_iou: 0.8304 - val_accuracy: 0.9938\n",
      "Epoch 3/3\n",
      "245/246 [============================>.] - ETA: 1s - loss: 0.0114 - iou: 0.8820 - accuracy: 0.9955\n",
      "Epoch 00003: iou improved from 0.86682 to 0.88190, saving model to trained_models/segnet_original.h5\n",
      "246/246 [==============================] - 321s 1s/step - loss: 0.0114 - iou: 0.8819 - accuracy: 0.9955 - val_loss: 0.0172 - val_iou: 0.8209 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8cc902b910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TensorBoard(log_dir='training_logs/segnet_original_log', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='trained_models/segnet_original.h5', monitor='iou', save_best_only='True', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='min', monitor='val_loss', patience=50, verbose=1)\n",
    "callbacks = [tb, mc, es]\n",
    "model=SegNet(input_shape=(256, 256, 3), batch_size=16, n_labels=2, model_summary=True)\n",
    "batch_size = 16\n",
    "num_epochs = 25\n",
    "model.fit(prepare_data.train_data_generator(batch_size=16),\n",
    "                    validation_data=prepare_data.validation_data_generator(batch_size=16),epochs=num_epochs, \n",
    "                    verbose=1,steps_per_epoch=246, validation_steps=84,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build enceder done..\n",
      "Build decoder done..\n",
      "Model: \"SegNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(16, 256, 256, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (16, 256, 256, 64)   1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (16, 256, 256, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (16, 256, 256, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (16, 256, 256, 64)   36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (16, 256, 256, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (16, 256, 256, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_10 (M [(16, 128, 128, 64), 0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (16, 128, 128, 128)  73856       max_pooling_with_argmax2d_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (16, 128, 128, 128)  512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (16, 128, 128, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (16, 128, 128, 128)  147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (16, 128, 128, 128)  512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (16, 128, 128, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_11 (M [(16, 64, 64, 128),  0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (16, 64, 64, 128)    147584      max_pooling_with_argmax2d_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (16, 64, 64, 128)    512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (16, 64, 64, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (16, 64, 64, 128)    147584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (16, 64, 64, 128)    512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (16, 64, 64, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (16, 64, 64, 128)    147584      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (16, 64, 64, 128)    512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (16, 64, 64, 128)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_12 (M [(16, 32, 32, 128),  0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (16, 32, 32, 256)    295168      max_pooling_with_argmax2d_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (16, 32, 32, 256)    1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (16, 32, 32, 256)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (16, 32, 32, 256)    590080      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (16, 32, 32, 256)    1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (16, 32, 32, 256)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (16, 32, 32, 256)    590080      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (16, 32, 32, 256)    1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (16, 32, 32, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_13 (M [(16, 16, 16, 256),  0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (16, 16, 16, 256)    590080      max_pooling_with_argmax2d_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (16, 16, 16, 256)    1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (16, 16, 16, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (16, 16, 16, 256)    590080      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (16, 16, 16, 256)    1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (16, 16, 16, 256)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (16, 16, 16, 256)    590080      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (16, 16, 16, 256)    1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (16, 16, 16, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_14 (M [(16, 8, 8, 256), (1 0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_10 (MaxUnpoolin (16, 16, 16, 256)    0           max_pooling_with_argmax2d_14[0][0\n",
      "                                                                 max_pooling_with_argmax2d_14[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (16, 16, 16, 256)    590080      max_unpooling2d_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (16, 16, 16, 256)    1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (16, 16, 16, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (16, 16, 16, 256)    590080      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (16, 16, 16, 256)    1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (16, 16, 16, 256)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (16, 16, 16, 256)    590080      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (16, 16, 16, 256)    1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (16, 16, 16, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_11 (MaxUnpoolin (16, 32, 32, 256)    0           activation_67[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_13[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (16, 32, 32, 256)    590080      max_unpooling2d_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (16, 32, 32, 256)    1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (16, 32, 32, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (16, 32, 32, 256)    590080      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (16, 32, 32, 256)    1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (16, 32, 32, 256)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (16, 32, 32, 256)    590080      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (16, 32, 32, 256)    1024        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (16, 32, 32, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (16, 32, 32, 128)    32896       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_12 (MaxUnpoolin (16, 64, 64, 128)    0           conv2d_77[0][0]                  \n",
      "                                                                 max_pooling_with_argmax2d_12[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (16, 64, 64, 128)    147584      max_unpooling2d_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (16, 64, 64, 128)    512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (16, 64, 64, 128)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (16, 64, 64, 128)    147584      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (16, 64, 64, 128)    512         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (16, 64, 64, 128)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (16, 64, 64, 128)    147584      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (16, 64, 64, 128)    512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (16, 64, 64, 128)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_13 (MaxUnpoolin (16, 128, 128, 128)  0           activation_73[0][0]              \n",
      "                                                                 max_pooling_with_argmax2d_11[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (16, 128, 128, 128)  147584      max_unpooling2d_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (16, 128, 128, 128)  512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (16, 128, 128, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (16, 128, 128, 128)  147584      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (16, 128, 128, 128)  512         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (16, 128, 128, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (16, 128, 128, 64)   8256        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_14 (MaxUnpoolin (16, 256, 256, 64)   0           conv2d_83[0][0]                  \n",
      "                                                                 max_pooling_with_argmax2d_10[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (16, 256, 256, 64)   36928       max_unpooling2d_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (16, 256, 256, 64)   256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (16, 256, 256, 64)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (16, 256, 256, 64)   36928       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (16, 256, 256, 64)   256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (16, 256, 256, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (16, 256, 256, 2)    130         activation_77[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,360,450\n",
      "Trainable params: 8,351,234\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1360 images belonging to 2 classes.\n",
      "Found 1360 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "85/85 [==============================] - 68s 797ms/step - loss: 0.0125 - iou: 0.8048 - accuracy: 0.9959\n",
      "[0.012450580824823941, 0.8047909, 0.9959435]\n"
     ]
    }
   ],
   "source": [
    "model=SegNet(input_shape=(256, 256, 3), batch_size=16, n_labels=2, model_summary=True)\n",
    "model.load_weights('trained_models/segnet_original.h5')\n",
    "result=model.evaluate(prepare_data.test_data_generator(batch_size=16),steps=85)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build enceder done..\n",
      "Build decoder done..\n",
      "Model: \"SegNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(16, 256, 256, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (16, 256, 256, 64)   1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (16, 256, 256, 64)   256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (16, 256, 256, 64)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (16, 256, 256, 64)   36928       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (16, 256, 256, 64)   256         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (16, 256, 256, 64)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_20 (M [(16, 128, 128, 64), 0           activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (16, 128, 128, 128)  73856       max_pooling_with_argmax2d_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (16, 128, 128, 128)  512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (16, 128, 128, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (16, 128, 128, 128)  147584      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (16, 128, 128, 128)  512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (16, 128, 128, 128)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_21 (M [(16, 64, 64, 128),  0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (16, 64, 64, 128)    147584      max_pooling_with_argmax2d_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (16, 64, 64, 128)    512         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (16, 64, 64, 128)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (16, 64, 64, 128)    147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (16, 64, 64, 128)    512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (16, 64, 64, 128)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (16, 64, 64, 128)    147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (16, 64, 64, 128)    512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (16, 64, 64, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_22 (M [(16, 32, 32, 128),  0           activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (16, 32, 32, 256)    295168      max_pooling_with_argmax2d_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (16, 32, 32, 256)    1024        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (16, 32, 32, 256)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (16, 32, 32, 256)    590080      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (16, 32, 32, 256)    1024        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (16, 32, 32, 256)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (16, 32, 32, 256)    590080      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (16, 32, 32, 256)    1024        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (16, 32, 32, 256)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_23 (M [(16, 16, 16, 256),  0           activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (16, 16, 16, 256)    590080      max_pooling_with_argmax2d_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (16, 16, 16, 256)    1024        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (16, 16, 16, 256)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (16, 16, 16, 256)    590080      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (16, 16, 16, 256)    1024        conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (16, 16, 16, 256)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (16, 16, 16, 256)    590080      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (16, 16, 16, 256)    1024        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (16, 16, 16, 256)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling_with_argmax2d_24 (M [(16, 8, 8, 256), (1 0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_20 (MaxUnpoolin (16, 16, 16, 256)    0           max_pooling_with_argmax2d_24[0][0\n",
      "                                                                 max_pooling_with_argmax2d_24[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (16, 16, 16, 256)    590080      max_unpooling2d_20[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (16, 16, 16, 256)    1024        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (16, 16, 16, 256)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (16, 16, 16, 256)    590080      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (16, 16, 16, 256)    1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (16, 16, 16, 256)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (16, 16, 16, 256)    590080      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (16, 16, 16, 256)    1024        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (16, 16, 16, 256)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_21 (MaxUnpoolin (16, 32, 32, 256)    0           activation_119[0][0]             \n",
      "                                                                 max_pooling_with_argmax2d_23[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (16, 32, 32, 256)    590080      max_unpooling2d_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (16, 32, 32, 256)    1024        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (16, 32, 32, 256)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (16, 32, 32, 256)    590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (16, 32, 32, 256)    1024        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (16, 32, 32, 256)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (16, 32, 32, 256)    590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (16, 32, 32, 256)    1024        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (16, 32, 32, 256)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (16, 32, 32, 128)    32896       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_22 (MaxUnpoolin (16, 64, 64, 128)    0           conv2d_135[0][0]                 \n",
      "                                                                 max_pooling_with_argmax2d_22[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (16, 64, 64, 128)    147584      max_unpooling2d_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (16, 64, 64, 128)    512         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (16, 64, 64, 128)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (16, 64, 64, 128)    147584      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (16, 64, 64, 128)    512         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (16, 64, 64, 128)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (16, 64, 64, 128)    147584      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (16, 64, 64, 128)    512         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (16, 64, 64, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_23 (MaxUnpoolin (16, 128, 128, 128)  0           activation_125[0][0]             \n",
      "                                                                 max_pooling_with_argmax2d_21[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (16, 128, 128, 128)  147584      max_unpooling2d_23[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (16, 128, 128, 128)  512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (16, 128, 128, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (16, 128, 128, 128)  147584      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (16, 128, 128, 128)  512         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (16, 128, 128, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (16, 128, 128, 64)   8256        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_unpooling2d_24 (MaxUnpoolin (16, 256, 256, 64)   0           conv2d_141[0][0]                 \n",
      "                                                                 max_pooling_with_argmax2d_20[0][1\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (16, 256, 256, 64)   36928       max_unpooling2d_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (16, 256, 256, 64)   256         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (16, 256, 256, 64)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (16, 256, 256, 64)   36928       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (16, 256, 256, 64)   256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (16, 256, 256, 64)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (16, 256, 256, 2)    130         activation_129[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,360,450\n",
      "Trainable params: 8,351,234\n",
      "Non-trainable params: 9,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1360 images belonging to 2 classes.\n",
      "Found 1360 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "model=SegNet(input_shape=(256, 256, 3), batch_size=16, n_labels=2, model_summary=True)\n",
    "model.load_weights('trained_models/segnet_original.h5')\n",
    "flag=2\n",
    "testing_gen = prepare_data.test_data_generator(batch_size=16, seed=13)\n",
    "#testing_gen=PrepareData.images_without_label_data_generator(batch_size=16)\n",
    "while(flag>0):\n",
    "    flag=flag-1\n",
    "    batch_img, batch_mask= next(testing_gen)\n",
    "    #batch_img = next(testing_gen)\n",
    "    pred_all = model.predict(batch_img)\n",
    "    np.shape(pred_all)\n",
    "\n",
    "    for i in range(0, np.shape(pred_all)[0]):\n",
    "        fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "        ax1 = fig.add_subplot(1, 3, 1)\n",
    "        ax1.imshow(batch_img[i])\n",
    "        ax1.title.set_text('Original Image')\n",
    "        ax1.grid(b=None)\n",
    "\n",
    "        ax2 = fig.add_subplot(1, 3, 2)\n",
    "        ax2.set_title('Ground truth labels')\n",
    "        ax2.imshow(prepare_data.onehot_to_rgb(batch_mask[i], prepare_data.id2code))\n",
    "        ax2.grid(b=None)\n",
    "\n",
    "        ax3 = fig.add_subplot(1, 3, 3)\n",
    "        ax3.set_title('Predicted labels')\n",
    "        #Use a different color for prediction\n",
    "        new_color_code={0: (0, 0, 0), 1: (135,206,235)}\n",
    "        ax3.imshow(prepare_data.onehot_to_rgb(pred_all[i], new_color_code))\n",
    "        ax3.grid(b=None)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir segnet_original_log\n",
    "#!tensorboard --logdir /tmp/whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 2777\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
